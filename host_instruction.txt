Hosting and Deployment Instructions for cRAG
============================================

Part 1 — Upload the code to GitHub
----------------------------------
1) Create an empty repo on GitHub
   - Go to https://github.com/new and create a repository (e.g. crag).
   - Copy the HTTPS remote URL (e.g. https://github.com/<you>/crag.git).

2) Initialize git in your local project (if not already)
   cd /path/to/cRAG_GPT
   git init
   git add -A
   git commit -m "Initial import"

3) Add remote and push
   git branch -M main
   git remote add origin https://github.com/<you>/crag.git
   git push -u origin main

Notes:
- .gitignore already excludes large/runtime content (vectorstore, uploads, results, logs, node_modules, etc.).
- Do NOT commit your .env file or credentials to Git; keep secrets out of the repo.


Part 2 — Provision a brand‑new CentOS host
-----------------------------------------
Assumptions:
- You’ll run the app under a dedicated user (crag) using Gunicorn, behind Nginx.
- Python 3.10+ is recommended.
- The app requires Pandoc (for .docx -> Markdown conversion) and (optionally) Redis for multi‑worker mode.

0) Create system user and directories
   sudo useradd -m -r -s /bin/bash crag || true
   sudo mkdir -p /opt/crag
   sudo chown -R crag:crag /opt/crag

1) Install OS packages
   # CentOS 7/8 (use dnf on newer releases; yum on older)
   sudo yum -y update
   sudo yum -y install epel-release
   sudo yum -y install python3 python3-devel gcc gcc-c++ make openssl-devel libffi-devel git nginx redis pandoc
   # Helpful if some wheels require build toolchain
   sudo yum -y install rust cargo cmake || true

   # (Optional) If SELinux is Enforcing and you use Nginx as reverse proxy:
   # allow Nginx to connect to upstream services
   sudo setsebool -P httpd_can_network_connect 1 || true

2) Clone the repo into /opt/crag
   sudo -u crag -H bash -lc "cd /opt/crag && git clone https://github.com/<you>/crag.git app"

3) Create virtualenv and install Python deps
   sudo -u crag -H bash -lc "python3 -m venv /opt/crag/venv"
   sudo -u crag -H bash -lc "/opt/crag/venv/bin/pip install --upgrade pip setuptools wheel"
   sudo -u crag -H bash -lc "/opt/crag/venv/bin/pip install -r /opt/crag/app/requirements.txt"

   # Verify pandoc is available for pypandoc
   pandoc --version

4) Configure environment
   # Create an env file read by systemd services
   sudo tee /etc/crag.env >/dev/null <<'EOF'
SECRET_KEY=please-change-me
DEBUG=0

# Azure OpenAI (update with your values)
GPT_ENDPOINT=https://<your-azure-endpoint>
GPT_KEY=<your-azure-api-key>
GPT_DEPLOYMENT_NAME_4_1=<your-gpt-4.1-deployment>

# Azure Embeddings (text-embedding-3-large)
TE3L_ENDPOINT=https://<your-azure-embeddings-endpoint>
TE3L_KEY=<your-azure-embeddings-key>

# Optional: enable Redis-backed limiter + tasks + RQ workers
USE_REDIS_TASKS=1
REDIS_URL=redis://127.0.0.1:6379/0
LIMITER_STORAGE_URI=redis://127.0.0.1:6379/0
USE_RQ_TASKS=1
RQ_QUEUE_NAME=docjobs
RQ_JOB_TIMEOUT=7200

# Optional logging
LOG_DIR=/opt/crag/app/logs
EOF

   # Edit credentials in code for corpus management login (internal use):
   #   - Open /opt/crag/app/config.py and set Config.LOGIN / Config.PASSWORD.
   #   - Or keep defaults for a closed, internal network.

5) Prepare runtime folders (first start will create them automatically)
   # The app ensures required folders on startup, but you can pre-create and set permissions:
   sudo -u crag -H bash -lc "mkdir -p /opt/crag/app/{uploads,docx_results,documents,logs,work_results,full_prompt,extracted_files}"
   sudo -u crag -H bash -lc "mkdir -p /opt/crag/app/vectorstore"

6) Systemd service for Gunicorn (web)
   sudo tee /etc/systemd/system/crag.service >/dev/null <<'EOF'
[Unit]
Description=cRAG web (Gunicorn)
After=network.target

[Service]
Type=simple
User=crag
Group=crag
WorkingDirectory=/opt/crag/app
EnvironmentFile=/etc/crag.env
ExecStart=/opt/crag/venv/bin/gunicorn -c gunicorn.conf.py app:app
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

7) Systemd service for RQ worker (background doc processing)
   sudo tee /etc/systemd/system/crag-rq-worker.service >/dev/null <<'EOF'
[Unit]
Description=cRAG RQ worker (docjobs)
After=network.target redis.service

[Service]
Type=simple
User=crag
Group=crag
WorkingDirectory=/opt/crag/app
EnvironmentFile=/etc/crag.env
ExecStart=/opt/crag/venv/bin/rq worker -u ${REDIS_URL} ${RQ_QUEUE_NAME}
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

8) Nginx site config (reverse proxy)
   sudo tee /etc/nginx/conf.d/crag.conf >/dev/null <<'EOF'
server {
    listen 80;
    server_name _;

    client_max_body_size 20m;  # match Flask MAX_CONTENT_LENGTH

    location /static/ {
        alias /opt/crag/app/static/;
        access_log off;
        expires 7d;
    }

    # SSE endpoints need proxy buffering disabled
    location /api/progress/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 3600;
        proxy_send_timeout 3600;
        proxy_buffering off;
        add_header X-Accel-Buffering no;
    }

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
EOF

9) Enable and start services
   sudo systemctl daemon-reload
   sudo systemctl enable --now redis
   sudo systemctl enable --now crag.service
   sudo systemctl enable --now crag-rq-worker.service
   sudo systemctl enable --now nginx

10) Firewall (if enabled)
   sudo firewall-cmd --add-service=http --permanent || true
   sudo firewall-cmd --reload || true

11) Verify
   # Health endpoint
   curl -s http://127.0.0.1/api/health | jq . || curl -s http://127.0.0.1/api/health

   # Open in browser: http://<server ip>/
   # Use “Увійти” (login) at top‑right for Documents management (uses Config.LOGIN/PASSWORD).

12) Optional: scheduled maintenance
   # Nightly vectorstore sync (detect changes in documents/ and upsert/delete):
   sudo tee /etc/systemd/system/crag-sync.service >/dev/null <<'EOF'
[Unit]
Description=cRAG vectorstore sync
After=network.target redis.service

[Service]
Type=oneshot
User=crag
Group=crag
WorkingDirectory=/opt/crag/app
EnvironmentFile=/etc/crag.env
ExecStart=/opt/crag/venv/bin/python scripts/sync_vectorstore.py
EOF

   sudo tee /etc/systemd/system/crag-sync.timer >/dev/null <<'EOF'
[Unit]
Description=Daily cRAG vectorstore sync

[Timer]
OnCalendar=*-*-* 02:30:00
Persistent=true

[Install]
WantedBy=timers.target
EOF

   # Old results cleanup (older than 30 days):
   sudo tee /etc/systemd/system/crag-cleanup.service >/dev/null <<'EOF'
[Unit]
Description=cRAG results cleanup
After=network.target

[Service]
Type=oneshot
User=crag
Group=crag
WorkingDirectory=/opt/crag/app
ExecStart=/opt/crag/venv/bin/python scripts/cleanup_results.py --days 30 --root /opt/crag/app/docx_results
EOF

   sudo tee /etc/systemd/system/crag-cleanup.timer >/dev/null <<'EOF'
[Unit]
Description=Daily cRAG results cleanup

[Timer]
OnCalendar=*-*-* 03:00:00
Persistent=true

[Install]
WantedBy=timers.target
EOF

   sudo systemctl daemon-reload
   sudo systemctl enable --now crag-sync.timer crag-cleanup.timer


Troubleshooting
---------------
- Pandoc missing: pypandoc will fail; run `pandoc --version` and install via yum.
- Azure/OpenAI creds: check `/etc/crag.env` values and ensure outbound connectivity.
- Redis not required for single‑worker mode; but needed for multi‑worker resilience.
- Logs: `/opt/crag/app/logs/app.log` and `journalctl -u crag.service -f`.
- Test endpoints: `/api/health`, `/api/results`, `/api/corpus/list` (requires login; corpus APIs return 401 if not logged in).

